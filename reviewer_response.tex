\documentclass{aiaa-tc}

\title{reviewer responses for: \\ A Graph Theoretic Approach to Problem Formulation for 
Multidisciplinary Design Analysis and Optimization}

\usepackage{color}

\newenvironment{rev}{\vspace{2em}\itshape \textcolor{red}}{}


\begin{document}
\maketitle

\section{Reviewer 1}

\rev{This idea of PSG was mentioned but was not covered in 
the paper. For completeness and value proposition sake, I would recommend to 
add at least half section to show how it will help and look like. You can 
take the simplest formulation of your choice and show how MCG and FPG will 
translate and look as a PSG. A brief discussion of advantages vs 
disadvantages will be useful. }

We agree that this was too quickly addressed in the paper. While we feel that 
discussion of the PSG in any significant depth is too big of a topic to fit into 
this paper, it does warrant a more complete description than was given in the 
original draft. 

We have added sections 3.5, 4.4 in the appropriate 
parts of the paper to address the the driver nodes and driven edges which 
together distinguish a PSG from and FPG.  We have also added added section 5.5
which gives an example of a simple PSG and compares a PSG with its close relative
and XDSM diagram. 

It is our conclusion that the PSG represents a sub-set of the information in the XDSM
diagram, but that for data connectivity part of the graphs XDSM and PSG represent 
equivalent graphs. It would be interesting future work to consider incorporating a new
process edge type into the PSG to make it functionally equivalent to a complete XDSM, 
however that would be a significant amount of extra work and worth of it's own paper. 
To do that topic justice, the original XDSM work would need to be converted for every 
case considered into the proposed syntax to ensure that they were completely equivalent.

\rev{ The idea of “holes” and “collision” is explained a few times in the paper. 
It can be reduced. }

Searching the paper, the concepts is discussed often, but only formally defined once 
in section 4.1. In 5.3 a mathematical description of the set of nodes that meet
the criteria for holes and edges is given, but this is different than the definition. 

We have checked both sections and removed the gross reducency, but feel that keeping 
both equations makes for a clearer message in the paper. The concept is a bit subtle 
since a node can be either a design variable or a hole, but not both. Similarlly, 
a collision can occur when a variable has two incomming edges or not if the problem 
is multi-fidelity. So a little extra explanation helps to keep this clear. 

\rev{The review of other graph based techniques is good and highlights their 
limitations, but I would like to see a discussion of what challenges a 
practitioner may face while trying to use the approach suggested in this 
paper. The MCG and FPG will cover lot of information like objectives and 
constraints, but at what expense. Comparing XDSM with MCG or FPG, one might 
find XDSM as more easy to read and comprehend. For a similar size problem, 
FPG looks far more complex and bigger.}

We agree that XDSM is more visually informative and consise. However this was not the 
goal of the new syntax. Instead, the goal was to make a graph structure that 
was easier to operate on algorithmically. As a consequence the graph grows larger and 
less human readable. This trade is acceptable for two reasons: 

\begin{enumerate}
    \item It should be possible to convert between the XDSM format and the proposed syntax 
    in a lossless manner. This is true for the gray lines of XDSM but not the black ones.
    Only data connections are shown in current syntax. 
    \item Algorithmic methods are a useful way of analyzing problem structure and it makes 
    sense to have a graph structure that works well for this use, even at the expense 
    of human readability. 
\end{enumerate}

See the revised end of the introduction (section 1) where this is more clearly stated. 

\rev{If PSG is covered even to a small 
extent (like explained in first comment) I would suggest or like to see the 
PSG equivalent of problem formulation shown in Figure 2 with XDSM.}

See new Fig. 8 and Fig. 13 


\rev{Is it really adding a lot of value to have graphs like MCG or FPG which 
are very explicit in nature and can become difficult to read}

Their value is not derived from their ability to represent the data in a human readable 
form, but in it's power as a machine readable one. Section 5.3 introduces an 
algorithm for testing if graphs are in fact reduced down to fundamental problems and 
to reduce them to one if they are not. As problems grow larger and more complex, 
this kind of algorithm becomes ever more valuable. 

It could be implemented into a framework or stand alone tool to help teams develop the
specifics of a design problem before they started working to code the modules and such. 
Section 6 shows that for even simple problems, the graph (as viewed by an algorithm) is 
non-trivial. It also shows that there are multiple ways to solve problems. As 
problems grow even a small amount from the size given in the example it's clear that 
algorithmic analysis useful. The graph syntax derives its usefulness from 
the effectiveness of describing the graph to a computer. 

\rev{Can the graph be compressed in a logical way to reduce the number of nodes 
and their interconnections while still conveying important and critical 
information for that stage (MCG stage or FPG stage) ? Reducing cycles is 
discussed but the graph may still look complex.

Looking at these graphs (for example Fig. 8), a node for example Z2 
appears several times. It may be useful to figure out holes and collision, 
but once it is resolved, can those nodes be consolidated to provide simpler 
visualization ?}

There are a number of ways the graph could be simplified down to make it more 
human readable, but this was not the primary goal of the work. You could combine 
variables or remove them all together and just represent component to component 
connections like a pure DSM. 

It should be possible to convert the entire PSG graph into the that used by the 
data-connectivity part of an XDSM. You would have all the information in a more 
compact and visually insightful form. You could always convert that back into the 
more verbose syntax here as well. We would argue that the XDSM is more human readable, 
but this syntax is a closer representation of how a framework would view the problem. 

Given our goals, the verbose nature of the graphs is a necessary side effect. 

\rev{As the problem size increases, how will it affect the size and complexity 
of such graphs.}

The answer to this question is not trivial, as it depends on a number of factors 
such as the number of analyses and the number of variables in those analyses. 
However, speaking roughly, you could measure the complexity of a graph by the total 
number of nodes and edges. 

So the number of nodes will grow roughly linearly with the number of analysis tools 
and the number of variables. The number of fixed edges will grow linearly with the number of variables as well. The number of connection edges depends entirely on the specifics of the problem, but since any variable can only have a finite number of incoming edges (usually 1, but maybe 2 or 3 in multi-fidelity case) you can avoid an unbounded 
growth there. So very roughly speaking, the graph will grow O(N+M) where N is the number 
of variables and M is the number of analyses. 

If you assume large problems have hundreds of components and millions of variables, 
you're talking about graphs with a few million nodes and edges. These are very large, but 
not outside the relm of what is manageable by todays graph libraries. 

\rev{
I will assume that creation of such a graph and interconnections will be 
expected to be done by some kind of software tool or wizard. A brief 
discussion about why this MCG, FPG and PSG idea is better to lead to such a 
system can be useful. Although this itself can be a separate research and 
paper, but why this idea can provide a better foundation can be valuable.
}

See the new section 2.4 for a short section describing our envisioned usage 
of the graph language. 

[TODO: Brian and David can flush this out better than me...]

\rev{Minor comments:
Section 1 Line 46: I think other commercial tools such as iSight, 
modeFRONTIER should also be mentioned since their usage is more widespread 
compared to OpenMDAO.}

Agreed. Done and incorporated into Section 1. 

\rev{Page 13 line 33 column 2: Typo : “Step (D) now PROCEDEDS … “}

fixed. 

\rev{Page 16 line 38 
column 2: Typo : “… formulations involving MULTIPLES analysis ….”}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Reviewer 2}

\rev{Page 1, Line 46: 2nd column...check spacing after ``ModelCenter''.}

\rev{Page 2, Line 38: 2nd column...as your motivation was really done in the 
Introduction section, consider changing the heading on section 2 to 
``Background'' or something similar.  You don't really provide motivation in 
this section anyhow.}

\rev{Page 3, Line 19, 1st column: change ``weather'' to ``whether''}

\rev{Page 3, Line 21, 2nd column: change ``descrition'' to ``description''}

\rev{Page 4, Line 37, 1st column: what does ``REMS'' stand for?}

\rev{Page 4, Line 45, 1st column: change ``REMS address'' to ``REMS addresses''}

\rev{Page 4, Lines 35 to 55, 1st column:  This paragraph is a bit awkward in 
structure.  In the second to last sentence you state, "REMS provides syntax 
for variables and functions but does not facilitate inclusion of solvers or 
optimizers in the graph."  The reader then expects your method to address 
these shortcomings in the next sentence but instead you state, "...the goal 
of allowing graphs to describe analysis couplings and more closely interact 
with existing design processes and MDAO frameworks," which you never really 
called out as a shortcoming of REMS in the first place.  I think you could 
improve the flow/wording here.}

\rev{Line 10, 1st column, Page 10:  This equation (missing a number) has a LOT of 
unions, variables, etc...in it.  It would help tremendously to provide a 
verbal description of at least one of these equations to help with 
translation into the real world.  This would be similar to what you did 
following the steps (1) to (4) in the next subsection.}

\rev{Lines 5 - 12, 2nd column, Page 12:  Just a general question spurred by the 
text here.  What criteria would be applied to determine which FPG is better 
than another?}

\rev{Line 57, 1st column, Page 13: change ``as a input'' to ``as an input''}

\rev{Now for the request of more significant importance.  This is coming from 
someone with significant experience in MDO and who uses a lot of the 
analysis tools you specified in your case study on a daily basis.  I really 
liked this article but felt it was lacking some punch in the results 
section.  This was namely in the form of quantitative results.  You vaguely 
give some in the form of the different resulting connectivity graphs and 
this was good but to really drive home the value of your research to a 
potential user I think you could do a bit better with very minimal work. 
The potential user of this methodology will be concerned with one of two 
things: 1) minimizing computational time or 2) increasing the accuracy of 
the results.  I think you've given examples of these two scenarios already 
in figures 15 and 16, so why not provide a table of the CPU times (1) and/or 
deviation from higher order analyses (2) for each of these graphs.  Doesn't 
have to necessarily be these two metrics but something to really tie the 
output of your methodology to something tangible for comparison purposes. 
You could even include the metrics for a randomly obtained FPG as a 
baseline.  Then the person reading the article can say, "Wow, given a set of 
analysis tools and a general problem, I can employ this method to obtain an 
FPG that significantly reduces my overall computational time." or "Wow, 
given a set of analysis tools and a general problem, I can employ this 
method to obtain an FPG that significantly improves my overall computational 
accuracy while keeping my computational efficiency as high as possible."}

\rev{If you are worried about length, I think the conclusions section may be cut 
in half and still accomplish its intended purpose.}

\section{Reviewer 3}

\rev{As the authors point out the design of a major product, such as a civil airliner, 
is complex and the level of complexity increases as design requirements change i.e. the 
need to reduce carbon emissions, the need to reduce maintenance downtime etc. and the 
number of design teams involved in creating a new product increases in number and 
distribution. Their paper is, I think, attempting to address the need to support 
design teams in confronting this situation but have not clearly defined where their work 
fits into the design process \\\\
Broadly speaking there are three major tasks or steps that have to be worked 
through when a globally distributed team is setting up a design system that allows it to 
effectively deploy an MDO methodology to support the design of a product such as a new 
civil airliner: 
\\\\1. The team must decide which design tools are required at each stage of the design 
process as the design proceeds down the time-line this includes the data flow required 
between the various design centers and the design history preservation requirements,
\\\\2. This combination of requirements must be converted into a set of interacting tools 
together with data flow and control programs that constitute a template for a 
Computational Design Engine (CDE),
\\\\3. Finally this template has to be instantiated into a usable CDE software system 
which might take advantage of commercially available software such as that found in Simula etc.
\\\\The paper is clearly focused on step 2 above and it advances a sound argument for the use 
of graph theory to establish an appropriate set of outcomes from such a step and, whilst 
it implies the existence of the other two steps, it does not state this early enough in 
the paper and with sufficient detail to allow a practicing engineer to understand the 
role being played by the authors contribution. I would recommend that the authors clearly 
define the role that their graph theoretic approach plays in this triple set of steps 
leading to the creation of effective CDE.}

The reviewer has correctly identified the major motivation for this work. The goal is indeed to 
assist engineers and teams of engineers in the process of building a model out of a set of interconnected 
tools. 

We believe that the distrinction between phases 1 and 2 from the comments are covered adequately 
in the bulk of the introduction and especially in the notional problem described there in. 

However, to clarify the disctinction between phases 2 and 3 we hav added the following near 
line 52, page 3 of the original submission: 

\emph{%
Our goal is to develop formalism for expressing analysis interconnectivity and for determining feasible
    analysis tool sets to assist an engineering team conducting this task. Because the problem deals with
    interconnectivity, we base our approach on the representations and techniques of graph theory.
    The approach begins by constructing the \emph{maximal connectivity graph (MCG)} describing all possible
    interconnections between the analysis tools proposed by the engineers. Graph operations are then
    conducted to reduce the MCG to a \emph{fundamental problem graph (FPG)} that describes the set of analysis
    tools needed to solve the specified system-level design problem. The concept of the FPG and 
    the identification of feasible FPGs from an MCG are the main contributions of the paper. \\\\
    This information in an FPG represents the engineering design problem that needs to be solved, but it is not 
    itself sufficient to actually run a design optimization. It does not provide infomration 
    about how to solve the problem. Even after the problem is defined an integration platform or framework needs 
    to be selected and appropriate optimization methods identified. This last step essentially 
    involves taking the FPG and turning it into a usable model. We breifly consider methods to further 
    manipulate the FPG into a \emph{problem solution graph (PSG)} which could be usefull in this 
    task, but that is not the focus of this paper. The work is primarily concerned with applying graph 
    theory to the creation of an FPG and the benefits to the design process by doing so.}

\end{document}